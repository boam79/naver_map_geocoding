/**
 * ë°°ì¹˜ ì²˜ë¦¬ ì„œë¹„ìŠ¤
 * ì£¼ì†Œ ì •ê·œí™” â†’ ì§€ì˜¤ì½”ë”© â†’ ê²°ê³¼ ì €ì¥
 */

import { normalizeAddress } from '@/lib/addr/normalize';
import { getGeocodeClient } from '@/lib/geocode/client';
import { jobStore } from './job-store';
import type { GeocodeResult } from '@/lib/geocode/types';
import type { ProcessedAddress } from './types';

export interface BatchProcessOptions {
  jobId: string;
  addresses: string[];
  checkpointInterval?: number;
  onProgress?: (processed: number, total: number) => void;
}

/**
 * ë°°ì¹˜ ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜
 */
export async function processBatch(options: BatchProcessOptions): Promise<ProcessedAddress[]> {
  const { jobId, addresses, checkpointInterval = 100, onProgress } = options;
  
  const results: ProcessedAddress[] = [];
  const geocodeClient = getGeocodeClient();
  
  // Job ìƒíƒœ ì—…ë°ì´íŠ¸
  jobStore.updateJob(jobId, { status: 'processing' });
  
  for (let i = 0; i < addresses.length; i++) {
    const originalAddress = addresses[i];
    
    try {
      // 1. ì£¼ì†Œ ì •ê·œí™”
      const normalized = normalizeAddress(originalAddress);
      
      // 2. ì§€ì˜¤ì½”ë”© (ì •ê·œí™”ëœ ì£¼ì†Œ ì‚¬ìš©)
      const geocodeResult = await geocodeClient.geocode(normalized.normalized);
      
      // 3. ê²°ê³¼ ì €ì¥
      const processed: ProcessedAddress = {
        originalAddress,
        normalizedAddress: normalized.normalized,
        lat: geocodeResult.lat,
        lng: geocodeResult.lng,
        confidence: Math.min(normalized.confidence, geocodeResult.confidence),
        status: geocodeResult.status === 'success' ? 'success' : 'failed',
        success: geocodeResult.status === 'success',
        error: geocodeResult.error,
        geocodeResponse: {
          roadAddress: geocodeResult.roadAddress,
          jibunAddress: geocodeResult.jibunAddress,
        },
      };
      
      results.push(processed);
      
      // 4. Job ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
      const job = jobStore.getJob(jobId);
      if (job) {
        jobStore.updateJob(jobId, {
          processedCount: i + 1,
          successCount: job.successCount + (processed.status === 'success' ? 1 : 0),
          failedCount: job.failedCount + (processed.status === 'failed' ? 1 : 0),
          currentAddress: originalAddress,
        });
      }
      
      // 5. ì²´í¬í¬ì¸íŠ¸ ì €ì¥
      if ((i + 1) % checkpointInterval === 0) {
        jobStore.addCheckpoint(jobId);
        
        // TODO: ì‹¤ì œë¡œëŠ” íŒŒì¼ë¡œ ì €ì¥
        console.log(`Checkpoint: ${i + 1}/${addresses.length}`);
      }
      
      // 6. ì§„í–‰ë¥  ì½œë°±
      if (onProgress) {
        onProgress(i + 1, addresses.length);
      }
    } catch (error) {
      console.error(`Error processing address ${i}:`, error);
      
      // ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ ê²°ê³¼ ì €ì¥
      results.push({
        originalAddress,
        normalizedAddress: originalAddress,
        confidence: 0,
        status: 'failed',
        success: false,
        error: error instanceof Error ? error.message : 'Unknown error',
      });
      
      const job = jobStore.getJob(jobId);
      if (job) {
        jobStore.updateJob(jobId, {
          processedCount: i + 1,
          failedCount: job.failedCount + 1,
        });
      }
    }
  }
  
  // ì™„ë£Œ
  const endTime = Date.now();
  const job = jobStore.getJob(jobId);
  const processingTime = job ? endTime - job.startTime : 0;
  
  // ê²°ê³¼ë¥¼ jobì— ì €ì¥
  jobStore.updateJob(jobId, {
    status: 'completed',
    endTime,
    results, // ê²°ê³¼ ë°ì´í„° ì €ì¥
  } as any);
  
  // ê²°ê³¼ íŒŒì¼ ì €ì¥
  try {
    await saveResults(jobId, results, processingTime);
    console.log(`âœ… Results saved successfully for job ${jobId}`);
  } catch (error) {
    console.error('âŒ Failed to save results:', error);
  }
  
  return results;
}

/**
 * ê²°ê³¼ íŒŒì¼ ì €ì¥
 */
async function saveResults(
  jobId: string,
  results: ProcessedAddress[],
  processingTime: number
): Promise<void> {
  const { writeFile, mkdir } = await import('fs/promises');
  const { join } = await import('path');
  const { OUTPUT_DIR } = await import('@/lib/utils/file-storage');
  const { generateMarkdownReport, generateReportFileName } = await import('@/lib/report/markdown');
  const { generateAddressCountCSV } = await import('@/lib/agg/address');
  
  // OUTPUT_DIR ì¡´ì¬ í™•ì¸ ë° ìƒì„±
  try {
    await mkdir(OUTPUT_DIR, { recursive: true });
    console.log(`ğŸ“ Output directory ready: ${OUTPUT_DIR}`);
  } catch (error) {
    console.error('Failed to create output directory:', error);
    throw error;
  }
  
  // 1. ì„±ê³µí•œ ê²°ê³¼ CSV
  const successResults = results.filter((r) => r.status === 'success');
  const successCSV = [
    'ì›ë³¸ì£¼ì†Œ,ì •ê·œí™”ëœì£¼ì†Œ,ìœ„ë„,ê²½ë„,ì‹ ë¢°ë„,ë„ë¡œëª…ì£¼ì†Œ,ì§€ë²ˆì£¼ì†Œ',
    ...successResults.map((r) =>
      [
        `"${r.originalAddress}"`,
        `"${r.normalizedAddress}"`,
        r.lat,
        r.lng,
        r.confidence,
        `"${r.geocodeResponse?.roadAddress || ''}"`,
        `"${r.geocodeResponse?.jibunAddress || ''}"`,
      ].join(',')
    ),
  ].join('\n');
  
  const resultsPath = join(OUTPUT_DIR, `results_${jobId}.csv`);
  await writeFile(resultsPath, successCSV, 'utf-8');
  console.log(`âœ… Saved results CSV: ${resultsPath}`);
  
  // 2. ì—ëŸ¬ CSV
  const errorResults = results.filter((r) => r.status === 'failed');
  if (errorResults.length > 0) {
    const errorCSV = [
      'ì›ë³¸ì£¼ì†Œ,ì—ëŸ¬ë©”ì‹œì§€',
      ...errorResults.map((r) => `"${r.originalAddress}","${r.error || 'ì•Œ ìˆ˜ ì—†ìŒ'}"`),
    ].join('\n');
    
    const errorsPath = join(OUTPUT_DIR, `errors_${jobId}.csv`);
    await writeFile(errorsPath, errorCSV, 'utf-8');
    console.log(`âœ… Saved errors CSV: ${errorsPath}`);
  }
  
  // 3. Markdown ë¦¬í¬íŠ¸
  const reportData = {
    jobId,
    fileName: `processed_${jobId}`,
    processedAt: new Date(),
    results,
    totalCount: results.length,
    successCount: successResults.length,
    failedCount: errorResults.length,
    processingTime,
  };
  
  const markdownContent = generateMarkdownReport(reportData, {
    topN: parseInt(process.env.DEFAULT_TOP_N || '20', 10),
    includeMap: true,
    includeErrors: true,
  });
  
  const reportFileName = generateReportFileName(jobId);
  const reportPath = join(OUTPUT_DIR, reportFileName);
  await writeFile(reportPath, markdownContent, 'utf-8');
  console.log(`âœ… Saved markdown report: ${reportPath}`);
  
  console.log(`ğŸ“¦ All results saved for job ${jobId}:
    - Results CSV: results_${jobId}.csv
    - Errors CSV: errors_${jobId}.csv (${errorResults.length} errors)
    - Report: ${reportFileName}
  `);
}

/**
 * ì¤‘ë³µ ì£¼ì†Œ ì‚¬ì „ ì œê±°
 * API í˜¸ì¶œ ìµœì í™”
 */
export function deduplicateForProcessing(
  addresses: string[]
): {
  unique: string[];
  indexMap: Map<string, number[]>; // ì •ê·œí™”ëœ ì£¼ì†Œ â†’ ì›ë³¸ ì¸ë±ìŠ¤ë“¤
} {
  const indexMap = new Map<string, number[]>();
  const seen = new Set<string>();
  const unique: string[] = [];
  
  addresses.forEach((addr, index) => {
    const normalized = normalizeAddress(addr).normalized;
    
    if (!seen.has(normalized)) {
      seen.add(normalized);
      unique.push(addr);
    }
    
    const indices = indexMap.get(normalized) || [];
    indices.push(index);
    indexMap.set(normalized, indices);
  });
  
  return { unique, indexMap };
}

